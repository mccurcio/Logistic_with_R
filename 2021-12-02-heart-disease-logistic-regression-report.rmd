---
title: "Analysis of Framingham Heart Study Using Logistic Regression"
author: "Report by Matthew Curcio"
date: "12/2/2021"
output: pdf_document
---

---

## Executive Summary

- The Framingham Heart Study (FHS) is a longitudinal study that investigated **4,133 participants**.
- The purpose of the FHS is to **determine the risk factors for cardiovascular disease** by following 14 variables.


--- 

## Disscussion

The goal of this study is to determine which conditions lead to a high probability of a person obtaining Cardiovascular Disease.  


- The `caret` package, short for **C**lassification And **RE**gression **T**raining, is used for analysis.
- The data is partitioned by `caret` to run 10X fold Cross-fold Validation repeated 5 times.
- The method is a general linear model (`glm`) using a binomial or Logistic Regression.
- The dependent variable `TenYearCHD` is an indicator for patients that had cardiovascular disease after 10 years.
- The model is fit with 14 independent variables.

| #   | Dependent variable | Variable Type |
| :-- | :----------------- | :------------ |
| 1   | TenYearCHD         | Factor(0,1)   |

| #   | Independent variable | Variable Type |
| :-- | :------------------- | :------------ |
| 1   | male1                | Factor(0,1)   |
| 2   | age                  | Continous     |
| 3   | education1           | Factor(0,1)   |
| 4   | currentSmoker1       | Factor(0,1)   |
| 5   | cigsPerDay           | Continous     |
| 6   | prevalentStroke1     | Factor(0,1)   |
| 7   | prevalentHyp1        | Factor(0,1)   |
| 8   | diabetes1            | Continous     |
| 9   | totChol              | Continous     |
| 10  | sysBP                | Continous     |
| 11  | diaBP                | Continous     |
| 12  | BMI                  | Continous     |
| 13  | heartRate            | Continous     |
| 14  | glucose              | Continous     |

```{r DONOTSHOW, message=FALSE, warning=FALSE, include=FALSE}
#DO NOT SHOW
options(tinytex.verbose = TRUE)

#Load Libraries
Libraries <- c("doMC", "knitr", "readr", "tidyverse", "caret", "skimr")
for (p in Libraries) { 
    library(p, character.only = TRUE)
}
opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE)

#Load Data
df <- read_csv("CHD_preprocessed.csv", 
     col_types = cols(male = col_factor(levels = c("0", "1")), 
                      education = col_factor(levels = c("0", "1")),
                      currentSmoker = col_factor(levels = c("0", "1")), 
                      BPMeds = col_skip(), 
                      prevalentStroke = col_factor(levels = c("0", "1")), 
                      prevalentHyp = col_factor(levels = c("0", "1")), 
                      diabetes = col_factor(levels = c("0", "1")), 
                      TenYearCHD = col_factor(levels = c("0", "1"))))

# Partition data into training and testing sets
set.seed(1000)
index <- createDataPartition(df$TenYearCHD, p = 0.8, list = FALSE)
training_set <- df[index, ]

# Create model, 10X fold CV repeated 5X
tcontrol <- trainControl(method = "repeatedcv",
                         number = 10,
                         repeats = 5)
```

---

### Logistic Regression Model Summary

```{r cache=TRUE}
model_obj <- train(TenYearCHD ~ .,
                   data = training_set,
                   trControl = tcontrol,
                   method = "glm",
                   family = "binomial")

summary(model_obj)
```

### Appendix 1 - Load Libraries

```{r message=FALSE, warning=FALSE}

Libraries <- c("knitr", "readr", "tidyverse", "caret", "skimr")
for (p in Libraries) { 
    library(p, character.only = TRUE)
}

opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE)
```

### Appendix 2 - Load Data

- The data from the Framingham Heart Study can be found at https://www.kaggle.com/captainozlem/framingham-chd-preprocessed-data.

```{r message=FALSE, warning=FALSE}
df <- read_csv("CHD_preprocessed.csv", 
     col_types = cols(male = col_factor(levels = c("0", "1")), 
                      education = col_factor(levels = c("0", "1")),
                      currentSmoker = col_factor(levels = c("0", "1")), 
                      BPMeds = col_factor(levels = c("0", "1")), 
                      prevalentStroke = col_factor(levels = c("0", "1")), 
                      prevalentHyp = col_factor(levels = c("0", "1")), 
                      diabetes = col_factor(levels = c("0", "1")), 
                      TenYearCHD = col_factor(levels = c("0", "1"))))
#View(df)
```

### Appendix 3 - Exploratory Data Analysis

- Find data set dimensions 

```{r}
number_cols = paste("Number of Columns: ", ncol(df), sep = "")
number_rows = paste("Number of Rows: ", nrow(df), sep = "")

print(number_cols)
print(number_rows)
```

- Investigate the data structure

```{r}
str(df, give.attr=FALSE)
```

##### Sum all the missing values within the dataframe.

- Inspection of the FHS data shows that there are 4133 missing values.
- Visual inspection shows that **Blood Pressure Medications was entirely missing**. 
- *Blood Pressure Medications* feature is removed.

```{r}
print(paste("Total number of missing values :", sum(is.na(df))))
```

#### Remove Blood Pressure Medications(BPMeds) from the FHS data.

```{r}
df_clean <- subset (df, select = -BPMeds)

number_cols = paste("Number of Columns: ", ncol(df_clean), sep = "")
number_rows = paste("Number of Rows: ", nrow(df_clean), sep = "")

print(number_cols)
print(number_rows)

print("Display missing values")
print(paste("Number of missing values", sum(is.na(df_clean))))
```

### Exploratory Data Report using `df_clean` data and the library `skimr`

```{r}
skim(df_clean)
```

### Appendix 4 - Create Data Partition & Setup Cross-Validation

```{r cache=TRUE}
# Partition data into training and testing sets
set.seed(1000)
index <- createDataPartition(df_clean$TenYearCHD, p = 0.8, list = FALSE)
training_set <- df_clean[index, ]

# Create model, 10X fold CV repeated 5X
tcontrol <- trainControl(method = "repeatedcv",
                         number = 10,
                         repeats = 5)
```






