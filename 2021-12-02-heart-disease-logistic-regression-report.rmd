---
title: "Analysis of Framingham Heart Study Using Logistic Regression"
author: "Report by Matthew Curcio"
date: "12-02-21"
output: html_document
---

---

## USE https://stats.idre.ucla.edu/r/dae/logit-regression/
for analysis

## Executive Summary

- The Framingham Heart Study (FHS) is a longitudinal study that investigated **4,133 participants**.
- The purpose of the FHS is to **determine the risk factors for cardiovascular disease** by following 14 variables.


The five most important factors that determine the risk of cardiac heart disease are:

- By being a men vs women, the log-odds of acquiring CHD is an increase of 0.527. 

- If there is a history of Hypertension, the log-odds of acquiring CHD increase by 0.332.

- For every year in age the log odds of acquiring CHD increase by 0.0602.

- For every Cigarettes/day the log odds of acquiring CHD increase by 0.0204.

- For every Systolic BP the log odds of acquiring CHD increase by 0.0133.



--- 

## Disscussion

The goal of this study is to determine which conditions lead to a high probability of a person acquiring cardiovascular disease.

Logistic regression is used to understand the relationship between the dependent variable and one or more independent variables by estimating probabilities using a logistic regression equation. This type of analysis can help you predict the likelihood of an event happening or a choice being made. [^2]

[^2]:https://www.ibm.com/topics/logistic-regression


- The dependent variable is the incidence of acquiring cardiac hear disease (CHD) after ten years from testing.  The variable name in this study is abbreviated `TenYearCHD`.

- The model is fit with 14 independent variables.

| No. | Dependent variable   | Variable Type |
| :-- | :------------------- | :------------ |
| 1   | Cardiac Heart Disease After Ten Years | Factor(0,1)   |

| No. | Independent variable | Variable Type |
| :-- | :------------------- | :------------ |
| 1   | male1                | Factor(0,1)   |
| 2   | age                  | Numeric       |
| 3   | education1           | Factor(0,1)   |
| 4   | currentSmoker1       | Factor(0,1)   |
| 5   | cigsPerDay           | Numeric       |
| 6   | prevalentStroke1     | Factor(0,1)   |
| 7   | prevalentHyp1        | Factor(0,1)   |
| 8   | diabetes1            | Numeric       |
| 9   | totChol              | Numeric       |
| 10  | sysBP                | Numeric       |
| 11  | diaBP                | Numeric       |
| 12  | BMI                  | Numeric       |
| 13  | heartRate            | Numeric       |
| 14  | glucose              | Numeric       |



| **Variable Importance**    | Estimate  | P-value  | Significance |
| :------------------------- | :-------- | :------- | :----------- |
| Male                       | 0.5269778 | 3.33e-06 | ***          |
| Age                        | 0.0601825 | < 2e-16  | ***          |
| Systolic BP                | 0.0132616 | 0.00074  | ***          |
| Cigarettes / day           | 0.0204103 | 0.00180  | **           |
| Glucose                    | 0.0060033 | 0.00886  | **           |
| Total cholesterol          | 0.0023762 | 0.04977  | *            |
| Prevalence of hypertension | 0.3317811 | 0.02119  | *            |


| **List of Factors/Variables with low or no significance** | P-value |
| :-------------------------------------------------------- | :------ |
| Education                                                 | 0.48802 |
| Current Smoker                                            | 0.97215 |
| Prevalence of Stroke                                      | 0.54001 |
| Diabetes                                                  | 0.21588 |
| Diastolic BP                                              | 0.89748 |
| BMI                                                       | 0.85959 |
| Heart Rate                                                | 0.19139 |



## Methodology

- The `caret` package, short for **C**lassification And **RE**gression **T**raining, is used for analysis. [^1]
- The data is partitioned by `caret` to run 10X fold Cross-fold Validation repeated 5 times.
- The method is a general linear model (`glm`) using a binomial or Logistic Regression.

[^1]:https://github.com/topepo/caret/

```{r DONOTSHOW, message=FALSE, warning=FALSE, include=FALSE}
#DO NOT SHOW
options(tinytex.verbose = TRUE)

#Load Libraries
Libraries <- c("doMC", "knitr", "readr", "tidyverse", "caret", "skimr")
for (p in Libraries) { 
    library(p, character.only = TRUE)
}
opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE)

#Load Data
df <- read_csv("CHD_preprocessed.csv", 
     col_types = cols(male = col_factor(levels = c("0", "1")), 
                      education = col_factor(levels = c("0", "1")),
                      currentSmoker = col_factor(levels = c("0", "1")), 
                      BPMeds = col_skip(), 
                      prevalentStroke = col_factor(levels = c("0", "1")), 
                      prevalentHyp = col_factor(levels = c("0", "1")), 
                      diabetes = col_factor(levels = c("0", "1")), 
                      TenYearCHD = col_factor(levels = c("0", "1"))))

# Partition data into training and testing sets
set.seed(1000)
index <- createDataPartition(df$TenYearCHD, p = 0.8, list = FALSE)
training_set <- df[index, ]

# Create model, 10X fold CV repeated 5X
tcontrol <- trainControl(method = "repeatedcv",
                         number = 10,
                         repeats = 5)
```

---

### Logistic Regression Model Summary

```{r cache=TRUE}
model_obj <- train(TenYearCHD ~ .,
                   data = training_set,
                   trControl = tcontrol,
                   method = "glm",
                   family = "binomial")

summary(model_obj)
```

### Appendix 1 - Load Libraries

```{r message=FALSE, warning=FALSE}

Libraries <- c("knitr", "readr", "tidyverse", "caret", "skimr")
for (p in Libraries) { 
    library(p, character.only = TRUE)
}

opts_chunk$set(cache=TRUE, warning=FALSE, message=FALSE)
```

### Appendix 2 - Load Data

- The data from the Framingham Heart Study can be found at https://www.kaggle.com/captainozlem/framingham-chd-preprocessed-data.

```{r message=FALSE, warning=FALSE}
df <- read_csv("CHD_preprocessed.csv", 
     col_types = cols(male = col_factor(levels = c("0", "1")), 
                      education = col_factor(levels = c("0", "1")),
                      currentSmoker = col_factor(levels = c("0", "1")), 
                      BPMeds = col_factor(levels = c("0", "1")), 
                      prevalentStroke = col_factor(levels = c("0", "1")), 
                      prevalentHyp = col_factor(levels = c("0", "1")), 
                      diabetes = col_factor(levels = c("0", "1")), 
                      TenYearCHD = col_factor(levels = c("0", "1"))))
#View(df)
```

### Appendix 3 - Exploratory Data Analysis

- Find data set dimensions 

```{r}
number_cols = paste("Number of Columns: ", ncol(df), sep = "")
number_rows = paste("Number of Rows: ", nrow(df), sep = "")

print(number_cols)
print(number_rows)
```

- Investigate the data structure

```{r}
str(df, give.attr=FALSE)
```

##### Sum all the missing values within the dataframe.

- Inspection of the FHS data shows that there are 4133 missing values.
- Visual inspection shows that **Blood Pressure Medications was entirely missing**. 
- *Blood Pressure Medications* feature is removed.

```{r}
print(paste("Total number of missing values :", sum(is.na(df))))
```

#### Remove Blood Pressure Medications(BPMeds) from the FHS data.

```{r}
df_clean <- subset (df, select = -BPMeds)

number_cols = paste("Number of Columns: ", ncol(df_clean), sep = "")
number_rows = paste("Number of Rows: ", nrow(df_clean), sep = "")

print(number_cols)
print(number_rows)

print("Display missing values")
print(paste("Number of missing values", sum(is.na(df_clean))))
```

### Exploratory Data Report using `df_clean` data and the library `skimr`

```{r}
skim(df_clean)
```

### Appendix 4 - Create Data Partition & Setup Cross-Validation

```{r cache=TRUE}
# Partition data into training and testing sets
set.seed(1000)
index <- createDataPartition(df_clean$TenYearCHD, p = 0.8, list = FALSE)
training_set <- df_clean[index, ]

# Create model, 10X fold CV repeated 5X
tcontrol <- trainControl(method = "repeatedcv",
                         number = 10,
                         repeats = 5)
```






